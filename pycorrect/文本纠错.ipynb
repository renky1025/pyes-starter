{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4de5f4-c19e-4717-9e83-8da07f505284",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.cnblogs.com/luohenyueji/p/17725774.html#21-%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99\n",
    "## ***windows 安装失败，建议 基于linux 尝试***\n",
    "##[自然语言处理] 基于pycorrector实现文本纠错 pip install -U pycorrector\n",
    "### 下载语言模型： https://deepspeech.bj.bcebos.com/zh_lm/zh_giga.no_cna_cmn.prune01244.klm\n",
    "### 放到目录： /home/user/.pycorrector/datasets 下即可使用\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d74d21b-463f-469f-89b9-0f29f523ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-11 16:44:00.181\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpycorrector.detector\u001b[0m:\u001b[36m_initialize_detector\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mLoaded language model: /home/user/.pycorrector/datasets/zh_giga.no_cna_cmn.prune01244.klm\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人群川流不息，少先队员应该为老人让座! [('穿流不息', '川流不息', 2, 6), ('因该', '应该', 11, 13), ('坐', '座', 17, 18)]\n"
     ]
    }
   ],
   "source": [
    "##文本纠错\n",
    "\n",
    "import pycorrector\n",
    "# include_symbol: 是否包含标点符号，默认为True\n",
    "# threshold: 纠错阈值，默认为57\n",
    "corrected_sent, detail = pycorrector.correct(\"人群穿流不息，少先队员因该为老人让坐!\",include_symbol=True,threshold=60)\n",
    "# corrected_sent: 纠错后的句子\n",
    "# detail: 纠错信息，[wrong, right, begin_pos, end_pos]\n",
    "print(corrected_sent, detail)\n",
    "\n",
    "#####2023-10-11 15:37:55.092 | DEBUG    | pycorrector.detector:_initialize_detector:89 - Loaded language model: /home/user/.pycorrector/datasets/zh_giga.no_cna_cmn.prune01244.klm\n",
    "#####人群川流不息，少先队员应该为老人让座! [('穿流不息', '川流不息', 2, 6), ('因该', '应该', 11, 13), ('坐', '座', 17, 18)]\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a37c0a-eda3-4351-9c37-1232be139a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['穿流不息', 2, 6, 'proper'], ['因该', 11, 13, 'word'], ['坐', 17, 18, 'char']]\n"
     ]
    }
   ],
   "source": [
    "##错误检测\n",
    "import pycorrector\n",
    " \n",
    "idx_errors = pycorrector.detect('人群穿流不息，少先队员因该为老人让坐!')\n",
    "print(idx_errors)\n",
    "##[['穿流不息', 2, 6, 'proper'], ['因该', 11, 13, 'word'], ['坐', 17, 18, 'char']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5120569-2cf5-49f9-ace8-cf4644c98397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这块名表带带相传  ->  ('这块名表代代相传', [('带带相传', '代代相传', 4, 8)])\n",
      "这块名表代代相传  ->  ('这块名表代代相传', [])\n",
      "这场比赛我甘败下风  ->  ('这场比赛我甘拜下风', [('甘败下风', '甘拜下风', 5, 9)])\n",
      "这场比赛我甘拜下封  ->  ('这场比赛我甘拜下风', [('甘拜下封', '甘拜下风', 5, 9)])\n",
      "早上在拼哆哆上买了点葡桃  ->  ('早上在拼多多上买了点葡桃', [('拼哆哆', '拼多多', 3, 6)])\n"
     ]
    }
   ],
   "source": [
    "##成语、专名纠错\n",
    "from pycorrector.proper_corrector import ProperCorrector\n",
    "from pycorrector import config\n",
    " \n",
    "m = ProperCorrector(proper_name_path=config.proper_name_path)\n",
    "x = [\n",
    "    '这块名表带带相传',\n",
    "    '这块名表代代相传',\n",
    "    '这场比赛我甘败下风',\n",
    "    '这场比赛我甘拜下封',\n",
    "    '早上在拼哆哆上买了点葡桃',\n",
    "]\n",
    " \n",
    "for i in x:\n",
    "    print(i, ' -> ', m.proper_correct(i))\n",
    "\n",
    "###\n",
    "###\n",
    "###这块名表带带相传  ->  ('这块名表代代相传', [('带带相传', '代代相传', 4, 8)])\n",
    "###这块名表代代相传  ->  ('这块名表代代相传', [])\n",
    "###这场比赛我甘败下风  ->  ('这场比赛我甘拜下风', [('甘败下风', '甘拜下风', 5, 9)])\n",
    "###这场比赛我甘拜下封  ->  ('这场比赛我甘拜下风', [('甘拜下封', '甘拜下风', 5, 9)])\n",
    "###早上在拼哆哆上买了点葡桃  ->  ('早上在拼多多上买了点葡桃', [('拼哆哆', '拼多多', 3, 6)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc55b1ad-1fad-4264-b30d-d9d0fd48b237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-11 16:44:17.602\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpycorrector.detector\u001b[0m:\u001b[36m_initialize_detector\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mLoaded language model: /home/user/.pycorrector/datasets/zh_giga.no_cna_cmn.prune01244.klm\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "买iphonex，要多少钱  ->  [['钱', 12, 13, 'char']] ('买iphonex，要多少钱', [])\n",
      "哪里卖苹果吧？请大叔给我让坐  ->  [] ('哪里卖苹果吧？请大叔给我让坐', [])\n",
      "共同实际控制人萧华、霍荣铨、张旗康  ->  [['霍荣铨', 10, 13, 'word'], ['张旗康', 14, 17, 'word']] ('共同实际控制人萧华、霍荣铨、张启康', [('张旗康', '张启康', 14, 17)])\n",
      "上述承诺内容系本人真实意思表示  ->  [['系', 6, 7, 'char']] ('上述承诺内容系本人真实意思表示', [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-11 16:44:21.707\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpycorrector.confusion_corrector\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m22\u001b[0m - \u001b[34m\u001b[1mLoaded confusion size: 13\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大家一哄而伞怎么回事  ->  [['一哄', 2, 4, 'word'], ['伞', 5, 6, 'char']] ('大家一哄而散怎么回事', [('伞', '散', 5, 6)])\n",
      "******************************************\n",
      "买iphonex，要多少钱  ->  ('买iphoneX，要多少钱', [['iphonex', 'iphoneX', 1, 8]])\n",
      "哪里卖苹果吧？请大叔给我让坐  ->  ('哪里卖苹果八？请大叔给我让坐', [['苹果吧', '苹果八', 3, 6]])\n",
      "共同实际控制人萧华、霍荣铨、张旗康  ->  ('共同实际控制人萧华、霍荣铨、张旗康', [['萧华', '萧华', 7, 9], ['张旗康', '张旗康', 14, 17]])\n",
      "上述承诺内容系本人真实意思表示  ->  ('上述承诺内容系本人真实意思表示', [])\n",
      "大家一哄而伞怎么回事  ->  ('大家一哄而散怎么回事', [['一哄而伞', '一哄而散', 2, 6]])\n"
     ]
    }
   ],
   "source": [
    "###自定义混淆集\n",
    "\n",
    "from pycorrector import ConfusionCorrector, Corrector\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    error_sentences = [\n",
    "        '买iphonex，要多少钱',  # 漏召回\n",
    "        '哪里卖苹果吧？请大叔给我让坐',  # 漏召回\n",
    "        '共同实际控制人萧华、霍荣铨、张旗康',  # 误杀\n",
    "        '上述承诺内容系本人真实意思表示',  # 正常\n",
    "        '大家一哄而伞怎么回事',  # 成语\n",
    "    ]\n",
    "    m = Corrector()\n",
    "    for i in error_sentences:\n",
    "        print(i, ' -> ', m.detect(i), m.correct(i))\n",
    " \n",
    "    print('*' * 42)\n",
    "    \n",
    "    # 自定义混淆集\n",
    "    custom_confusion = {'得事': '的事', '天地无垠': '天地无限', '交通先行': '交通限行', '苹果吧': '苹果八', 'iphonex': 'iphoneX', '小明同学': '小茗同学', '萧华': '萧华',\n",
    "                        '张旗康': '张旗康', '一哄而伞': '一哄而散', 'happt': 'happen', 'shylock': 'shylock', '份额': '份额', '天俺门': '天安门'}\n",
    "    m = ConfusionCorrector(custom_confusion_path_or_dict=custom_confusion)\n",
    "    for i in error_sentences:\n",
    "        print(i, ' -> ', m.confusion_correct(i))\n",
    "\n",
    "\n",
    "###买iphonex，要多少钱  ->  [['钱', 12, 13, 'char']] ('买iphonex，要多少钱', [])\n",
    "###**哪里卖苹果吧？请大叔给我让坐  ->  [] ('哪里卖苹果吧？请大叔给我让坐', [])\n",
    "###**共同实际控制人萧华、霍荣铨、张旗康  ->  [['霍荣铨', 10, 13, 'word'], ['张旗康', 14, 17, 'word']] ('共同实际控制人萧华、霍荣铨、张启康', [('张旗康', '张启康', 14, 17)])\n",
    "###**上述承诺内容系本人真实意思表示  ->  [['系', 6, 7, 'char']] ('上述承诺内容系本人真实意思表示', [])\n",
    "###**大家一哄而伞怎么回事  ->  [['一哄', 2, 4, 'word'], ['伞', 5, 6, 'char']] ('大家一哄而散怎么回事', [('伞', '散', 5, 6)])\n",
    "###********************************************\n",
    "###**买iphonex，要多少钱  ->  ('买iphoneX，要多少钱', [['iphonex', 'iphoneX', 1, 8]])\n",
    "###**哪里卖苹果吧？请大叔给我让坐  ->  ('哪里卖苹果八？请大叔给我让坐', [['苹果吧', '苹果八', 3, 6]])\n",
    "###**共同实际控制人萧华、霍荣铨、张旗康  ->  ('共同实际控制人萧华、霍荣铨、张旗康', [['萧华', '萧华', 7, 9], ['张旗康', '张旗康', 14, 17]])\n",
    "###**上述承诺内容系本人真实意思表示  ->  ('上述承诺内容系本人真实意思表示', [])\n",
    "###**大家一哄而伞怎么回事  ->  ('大家一哄而散怎么回事', [['一哄而伞', '一哄而散', 2, 6]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802c6c2-9688-4c3c-8a7d-cd63ae6f939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##自定义语言模型\n",
    "# 自定义模型路径\n",
    "lm_path = './custom.klm'\n",
    "model = Corrector(language_model_path=lm_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28382a15-923d-4ab0-aa67-7656ff370c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-11 16:44:24.958\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpycorrector.en_spell\u001b[0m:\u001b[36m_init\u001b[0m:\u001b[36m39\u001b[0m - \u001b[34m\u001b[1mload en spell data: /home/user/.local/lib/python3.8/site-packages/pycorrector/data/en/en.json.gz, size: 30120\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what happending? how to speling it, can you gorrect it? => what happening? how to spelling it, can you correct it?\n",
      "[('happending', 'happening', 5, 15), ('speling', 'spelling', 24, 31), ('gorrect', 'correct', 44, 51)]\n"
     ]
    }
   ],
   "source": [
    "###英文拼写纠错\n",
    "sent = \"what happending? how to speling it, can you gorrect it?\"\n",
    "corrected_text, details = pycorrector.en_correct(sent)\n",
    "print(sent, '=>', corrected_text)\n",
    "print(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0339eb48-4adf-4d08-9de1-d7b38a939d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-11 16:44:29.785\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpycorrector.en_spell\u001b[0m:\u001b[36m_init\u001b[0m:\u001b[36m39\u001b[0m - \u001b[34m\u001b[1mload en spell data: /home/user/.local/lib/python3.8/site-packages/pycorrector/data/en/en.json.gz, size: 30120\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is your name? shylock? => what is your name? shock? [('shylock', 'shock', 19, 26)]\n",
      "------------------------------------------\n",
      "what is your name? shylock? => what is your name? shylock? []\n"
     ]
    }
   ],
   "source": [
    "from pycorrector.en_spell import EnSpell\n",
    " \n",
    "# # 定义一个字符串变量\n",
    "sent = \"what is your name? shylock?\"  \n",
    "# 创建一个EnSpell类的实例对象\n",
    "spell = EnSpell()  \n",
    "corrected_text, details = spell.correct(sent) \n",
    "# shylock被纠错为shock\n",
    "print(sent, '=>', corrected_text, details) \n",
    "print('-' * 42) \n",
    " \n",
    "# 定义一个包含词频信息的字典\n",
    "# 设置shylock出现频次比shock高\n",
    "my_dict = {'your': 120, 'name': 2, 'is': 1, 'shock': 2, 'shylock': 1, 'what': 1} \n",
    "# 创建一个EnSpell类的实例对象，并传入自定义词频字典\n",
    "spell = EnSpell(word_freq_dict=my_dict)  \n",
    "corrected_text, details = spell.correct(sent)  \n",
    "print(sent, '=>', corrected_text, details)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7a6d215-64f8-4473-bac3-67dec6425bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "學而時習之，不亦說乎 => 学而时习之，不亦说乎\n",
      "学而时习之，不亦说乎 => 學而時習之，不亦說乎\n"
     ]
    }
   ],
   "source": [
    "###中文简繁互换\n",
    "import pycorrector\n",
    " \n",
    "traditional_sentence = '學而時習之，不亦說乎'\n",
    "simplified_sentence = pycorrector.traditional2simplified(traditional_sentence)\n",
    "print(traditional_sentence, '=>', simplified_sentence)\n",
    " \n",
    "simplified_sentence = '学而时习之，不亦说乎'\n",
    "traditional_sentence = pycorrector.simplified2traditional(simplified_sentence)\n",
    "print(simplified_sentence, '=>', traditional_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3aa8e3-661e-4444-ae32-699606b1f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "pycorrector提供多个基于深度学习的中文文本纠错模型，一般而言，使用深度学习进行中文文本纠错可以获得比基于规则纠错更好的效果。pycorrector在SIGHAN2015数据集数据集下对各种深度学习模型进行了评测，SIGHAN2015数据集是一个经典公开的用于中文文本纠错任务的数据集，并得出以下结论：\n",
    "\n",
    "中文拼写纠错模型效果最好的是MacBert-CSC，模型名称是shibing624/macbert4csc-base-chinese，huggingface model：shibing624/macbert4csc-base-chinese\n",
    "中文语法纠错模型效果最好的是BART-CSC，模型名称是shibing624/bart4csc-base-chinese，huggingface model：shibing624/bart4csc-base-chinese\n",
    "最具潜力的模型是Mengzi-T5-CSC，模型名称是shibing624/mengzi-t5-base-chinese-correction，huggingface model：shibing624/mengzi-t5-base-chinese-correction，未改变模型结构，仅fine-tune中文纠错数据集，已经在SIGHAN 2015取得接近SOTA的效果\n",
    "基于ChatGLM-6B的纠错微调模型效果也不错，模型名称是shibing624/chatglm-6b-csc-zh-lora，huggingface model：shibing624/chatglm-6b-csc-zh-lora，大模型不仅能改错还能润色句子，但是模型太大，推理速度慢\n",
    "在pycorrector中调用MacBert-CSC模型进行文本纠错的代码如下，该代码将自动加载macbert4csc-base-chinese提供的纠错模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8298ad3-8b5a-4ad4-81d5-3aec4ba67505",
   "metadata": {},
   "outputs": [],
   "source": [
    "##pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2a2db-e868-4602-9a34-29cc055cec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "###基于深度学习 纠错模型 推荐： git clone https://huggingface.co/shibing624/macbert4csc-base-chinese\n",
    "from pycorrector.macbert.macbert_corrector import MacBertCorrector\n",
    "from pycorrector import ConfusionCorrector\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    error_sentences = [\n",
    "        '少先队员因该为老人让坐',\n",
    "        '机七学习是人工智能领遇最能体现智能的一个分知',\n",
    "    ]\n",
    " \n",
    "    m = MacBertCorrector()\n",
    "    # add confusion corrector for postprocess\n",
    "    confusion_dict = {\"喝小明同学\": \"喝小茗同学\", \"老人让坐\": \"老人让座\", \"平净\": \"平静\", \"分知\": \"分支\"}\n",
    "    cm = ConfusionCorrector(custom_confusion_path_or_dict=confusion_dict)\n",
    "    for line in error_sentences:\n",
    "        correct_sent, err = m.macbert_correct(line)\n",
    "        print(\"query:{} => {} err:{}\".format(line, correct_sent, err))\n",
    "        correct_sent, err = cm.confusion_correct(correct_sent)\n",
    "        if err:\n",
    "            print(\"added confusion: {} err: {}\".format(correct_sent, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab3327c-7af7-433f-b852-2b4b7bb52669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
