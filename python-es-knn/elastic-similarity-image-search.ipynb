{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d985cb1b-3e75-4aec-90ee-7ce062b0a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3173, 0.1137, 0.1254]])\n"
     ]
    }
   ],
   "source": [
    "##### 和图片向量 相似的文本 \n",
    "## pip install Pillow\n",
    "## pip install sentence-transformers\n",
    "## pip install torchvision\n",
    "## pip install wrapt\n",
    "## pip install termcolor\n",
    "## pip install flatbuffers\n",
    "## download model ： git lfs clone https://huggingface.co/sentence-transformers/clip-ViT-B-32-multilingual-v1  --config \"http.proxy=http://127.0.0.1:7890\"\n",
    "## download model ： git lfs clone https://huggingface.co/sentence-transformers/clip-ViT-B-32  --config \"http.proxy=http://127.0.0.1:7890\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image\n",
    "\n",
    "#Load CLIP model\n",
    "model = SentenceTransformer('D:\\\\pyes-starter\\\\python-es-knn\\\\clip-ViT-B-32')\n",
    "\n",
    "#Encode an image:\n",
    "img_emb = model.encode(Image.open('two_dogs_in_snow.jpg'))\n",
    "\n",
    "#Encode text descriptions\n",
    "text_emb = model.encode(['Two dogs in the snow', 'A cat on a table', 'A picture of London at night'])\n",
    "\n",
    "#Compute cosine similarities \n",
    "cos_scores = util.cos_sim(img_emb, text_emb)\n",
    "print(cos_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d39f4d3-fe35-47c3-9cec-8f1aa9f62d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: A dog in the snow\n",
      "Score: tensor(0.3140)\n",
      "Path: https://unsplash.com/photos/QtxgNsmJQSs/download?ixid=MnwxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNjM1ODQ0MjY3&w=640 \n",
      "\n",
      "Text: Eine Katze\n",
      "Score: tensor(0.2667)\n",
      "Path: https://unsplash.com/photos/9UUoGaaHtNE/download?ixid=MnwxMjA3fDB8MXxzZWFyY2h8Mnx8Y2F0fHwwfHx8fDE2MzU4NDI1ODQ&w=640 \n",
      "\n",
      "Text: Una playa con palmeras.\n",
      "Score: tensor(0.3006)\n",
      "Path: https://unsplash.com/photos/Siuwr3uCir0/download?ixid=MnwxMjA3fDB8MXxzZWFyY2h8NHx8YmVhY2h8fDB8fHx8MTYzNTg0MjYzMg&w=640 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 文本转向量支持多语言， 更准确\n",
    "## 图像转向量\n",
    "## 文本和图片向量相似度查询 \n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image, ImageFile\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "# We use the original clip-ViT-B-32 for encoding images\n",
    "img_model = SentenceTransformer('D:\\\\pyes-starter\\\\python-es-knn\\\\clip-ViT-B-32')\n",
    "\n",
    "# Our text embedding model is aligned to the img_model and maps 50+\n",
    "# languages to the same vector space\n",
    "text_model = SentenceTransformer('D:\\\\pyes-starter\\\\python-es-knn\\\\clip-ViT-B-32-multilingual-v1')\n",
    "\n",
    "\n",
    "# Now we load and encode the images\n",
    "def load_image(url_or_path):\n",
    "    if url_or_path.startswith(\"http://\") or url_or_path.startswith(\"https://\"):\n",
    "        return Image.open(requests.get(url_or_path, stream=True).raw)\n",
    "    else:\n",
    "        return Image.open(url_or_path)\n",
    "\n",
    "# We load 3 images. You can either pass URLs or\n",
    "# a path on your disc\n",
    "img_paths = [\n",
    "    # Dog image\n",
    "    \"https://unsplash.com/photos/QtxgNsmJQSs/download?ixid=MnwxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNjM1ODQ0MjY3&w=640\",\n",
    "\n",
    "    # Cat image\n",
    "    \"https://unsplash.com/photos/9UUoGaaHtNE/download?ixid=MnwxMjA3fDB8MXxzZWFyY2h8Mnx8Y2F0fHwwfHx8fDE2MzU4NDI1ODQ&w=640\",\n",
    "\n",
    "    # Beach image\n",
    "    \"https://unsplash.com/photos/Siuwr3uCir0/download?ixid=MnwxMjA3fDB8MXxzZWFyY2h8NHx8YmVhY2h8fDB8fHx8MTYzNTg0MjYzMg&w=640\"\n",
    "]\n",
    "\n",
    "images = [load_image(img) for img in img_paths]\n",
    "\n",
    "# Map images to the vector space\n",
    "img_embeddings = img_model.encode(images)\n",
    "\n",
    "# Now we encode our text:\n",
    "texts = [\n",
    "    \"A dog in the snow\",\n",
    "    \"Eine Katze\",  # German: A cat\n",
    "    \"Una playa con palmeras.\"  # Spanish: a beach with palm trees\n",
    "]\n",
    "\n",
    "text_embeddings = text_model.encode(texts)\n",
    "\n",
    "# Compute cosine similarities:\n",
    "cos_sim = util.cos_sim(text_embeddings, img_embeddings)\n",
    "\n",
    "for text, scores in zip(texts, cos_sim):\n",
    "    max_img_idx = torch.argmax(scores)\n",
    "    print(\"Text:\", text)\n",
    "    print(\"Score:\", scores[max_img_idx] )\n",
    "    print(\"Path:\", img_paths[max_img_idx], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2df73-3147-49f4-a3e1-aface1049f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
